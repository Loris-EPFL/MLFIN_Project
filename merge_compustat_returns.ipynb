{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Merge processed compustat data (with new features and filled gaps from processed_data_compustat.csv using the preprocess_compustat_data.ipynb notebook) with the processed returns data (stock_returns_with_smoothing.csv) from preprocess_returns.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL9zH4vSveBQ",
        "outputId": "1f826d20-0a7c-4f87-a81d-e3962ccb4330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Mount using Collab\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "folder = '/content/gdrive/My Drive/datasets_mlfin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqMPY-Kov1fO"
      },
      "outputs": [],
      "source": [
        "#Load using collab mount\n",
        "returns_df = pd.read_csv(os.path.join(folder, 'stock_returns_with_smoothing.csv'))\n",
        "compustat_df = pd.read_csv(os.path.join(folder, 'processed_data_compustat.csv'))\n",
        "\n",
        "# Optionnal, load using PC if enough RAM\n",
        "# returns_df = pd.read_csv('datasets/PostProcessed/Returns/stock_returns_with_smoothing.csv')\n",
        "# compustat_df = pd.read_csv('datasets/PostProcesed/processed_data_compustat.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UvQoaQgvii1",
        "outputId": "e5eb9c08-eb63-412c-df79-7caefe1d6b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Returns dataset shape: (4566488, 18)\n",
            "Compustat dataset shape: (3848428, 43)\n",
            "Returns date range: 1925-12-31 00:00:00 to 2024-12-31 00:00:00\n",
            "Compustat date range: 1961-03-31 00:00:00 to 2025-04-30 00:00:00\n",
            "Common CUSIPs: 23200\n",
            "\n",
            "Merged dataset shape: (4566488, 60)\n",
            "Merged dataset unique CUSIPs: 52553\n",
            "Rows with Compustat data: 1608612\n",
            "Percentage with Compustat data: 35.22645849501849 %\n",
            "\n",
            "Missing value percentages for each predictor:\n",
            "epspxy: 64.92%\n",
            "oiadpy: 65.96%\n",
            "saley: 68.19%\n",
            "earnings_growth: 68.86%\n",
            "revenue_growth: 69.57%\n",
            "eps_surprise: 65.07%\n",
            "dividend_change: 88.77%\n",
            "repurchase_intensity: 73.47%\n",
            "\n",
            "Strict dataset (no missing values) shape: (490639, 61)\n",
            "\n",
            "Sample of strict dataset:\n",
            "           cusip   MthCalDt    MthRet   datadate  epspxy  oiadpy   saley  \\\n",
            "150706  86666510 1973-01-31  0.018182 1973-01-31    0.27   1.382   8.453   \n",
            "157898  86666510 1973-02-28 -0.080357 1973-02-28    0.27   1.382   8.453   \n",
            "168493  86666510 1973-04-30 -0.106383 1973-04-30    0.32   1.382  10.704   \n",
            "174122  86666510 1973-05-31 -0.059821 1973-05-31    0.32   1.382  10.704   \n",
            "184259  86666510 1973-07-31  0.525000 1973-07-31    0.32   1.382  10.704   \n",
            "\n",
            "        earnings_growth  revenue_growth  eps_surprise  dividend_change  \\\n",
            "150706         0.185714        0.011487          0.00              0.0   \n",
            "157898         0.185714        0.011487          0.00              0.0   \n",
            "168493         0.200803        0.266296          0.05              0.0   \n",
            "174122         0.200803        0.266296          0.05              0.0   \n",
            "184259         0.200803        0.266296          0.00              0.0   \n",
            "\n",
            "        repurchase_intensity  \n",
            "150706              0.039631  \n",
            "157898              0.039631  \n",
            "168493              0.031297  \n",
            "174122              0.031297  \n",
            "184259              0.031297  \n",
            "\n",
            "Final dataset shapes:\n",
            "Strict: X: (490639, 8) y: (490639,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Rename maj CUSIP to min cusip to match the column name\n",
        "returns_df = returns_df.rename(columns={'CUSIP': 'cusip'})\n",
        "\n",
        "returns_df['cusip'] = returns_df['cusip'].astype(str).str.strip().str[:8]\n",
        "compustat_df['cusip'] = compustat_df['cusip'].astype(str).str.strip().str[:8]\n",
        "\n",
        "# Convert dates to datetime (sanity check if not done previously)\n",
        "returns_df['MthCalDt'] = pd.to_datetime(returns_df['MthCalDt'])\n",
        "compustat_df['datadate'] = pd.to_datetime(compustat_df['datadate'])\n",
        "\n",
        "# Checks\n",
        "print(\"Returns dataset shape:\", returns_df.shape)\n",
        "print(\"Compustat dataset shape:\", compustat_df.shape)\n",
        "print(\"Returns date range:\", returns_df['MthCalDt'].min(), \"to\", returns_df['MthCalDt'].max())\n",
        "print(\"Compustat date range:\", compustat_df['datadate'].min(), \"to\", compustat_df['datadate'].max())\n",
        "print(\"Common CUSIPs:\", len(set(returns_df['cusip']) & set(compustat_df['cusip'])))\n",
        "\n",
        "# Perform the merge_asof merge\n",
        "merged_df = pd.merge_asof(\n",
        "    returns_df.sort_values('MthCalDt'),\n",
        "    compustat_df.sort_values('datadate'),\n",
        "    left_on='MthCalDt',\n",
        "    right_on='datadate',\n",
        "    by='cusip',\n",
        "    direction='backward',\n",
        "    tolerance=pd.Timedelta('7 days')  # Allow matching within the last 7 days\n",
        ")\n",
        "\n",
        "# Check the merge results\n",
        "print(\"\\nMerged dataset shape:\", merged_df.shape)\n",
        "print(\"Merged dataset unique CUSIPs:\", merged_df['cusip'].nunique())\n",
        "\n",
        "# Check rows with Compustat data\n",
        "merged_df['has_compustat'] = merged_df['datadate'].notna()\n",
        "print(\"Rows with Compustat data:\", merged_df['has_compustat'].sum())\n",
        "print(\"Percentage with Compustat data:\", merged_df['has_compustat'].mean() * 100, \"%\")\n",
        "\n",
        "# 9. Define the predictors we want to use\n",
        "predictors = [col for col in [\n",
        "    'epspxy', 'oiadpy', 'saley', 'earnings_growth',\n",
        "    'revenue_growth', 'eps_surprise', 'dividend_change',\n",
        "    'repurchase_intensity'\n",
        "] if col in merged_df.columns]\n",
        "\n",
        "# Ensure we have returns\n",
        "merged_df = merged_df.dropna(subset=['MthRet'])\n",
        "\n",
        "# Check missing value percentages for each predictor\n",
        "missing_percentages = merged_df[predictors].isna().mean() * 100\n",
        "print(\"\\nMissing value percentages for each predictor:\")\n",
        "for pred, pct in missing_percentages.items():\n",
        "    print(f\"{pred}: {pct:.2f}%\")\n",
        "\n",
        "# Only keep rows with Compustat data and no missing predictors\n",
        "merged_df_strict = merged_df[merged_df['has_compustat']].dropna(subset=predictors)\n",
        "print(\"\\nStrict dataset (no missing values) shape:\", merged_df_strict.shape)\n",
        "\n",
        "#Drop unused columns\n",
        "if 'available_date' in compustat_df.columns:\n",
        "    compustat_df.drop(columns=['available_date'])\n",
        "if 'has_compustat' in compustat_df.columns:\n",
        "    compustat_df.drop(columns=['has_compustat'])\n",
        "\n",
        "# save merged dataset\n",
        "merged_df_strict.to_csv(os.path.join(folder, 'merged_compustat_returns_cleaned_data_mv_avg.csv'), index=False)\n",
        "\n",
        "print(\"\\nSample of strict dataset:\")\n",
        "print(merged_df_strict[['cusip', 'MthCalDt', 'MthRet', 'datadate'] + predictors].head())\n",
        "\n",
        "print(\"\\nFinal dataset shapes:\")\n",
        "print(merged_df_strict.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we merge the moving average datasets and Compustat data with the sentiment Analysis data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from preprocessing.merge_sentiment_moving_average import (\n",
        "    create_custom_financial_dataset_with_sentiment_base,\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "first_df_path = 'merged_compustat_returns_cleaned_data_mv_avg.csv'\n",
        "second_df_path = 'merged_datasets_with_sentiment.csv'\n",
        "output_path = 'final_dataset_compustat_ma_sentiment.csv'\n",
        "\n",
        "merged_df = create_custom_financial_dataset_with_sentiment_base(first_df_path, second_df_path, output_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
